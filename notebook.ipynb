{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df1b5842",
   "metadata": {},
   "source": [
    "---\n",
    "### Contributors: Brian Waweru, Start-Date        : 08th May, 2025\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c391399",
   "metadata": {},
   "source": [
    "# 0.1 : Working Libraries and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c1c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Libraries\n",
    "import pandas as pd\n",
    "# sci-kit libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "# SMOTE \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# modelling and evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538400e",
   "metadata": {},
   "source": [
    "#### Importing the `dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7477355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3333, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account length  area code phone number international plan  \\\n",
       "0    KS             128        415     382-4657                 no   \n",
       "1    OH             107        415     371-7191                 no   \n",
       "2    NJ             137        415     358-1921                 no   \n",
       "\n",
       "  voice mail plan  number vmail messages  total day minutes  total day calls  \\\n",
       "0             yes                     25              265.1              110   \n",
       "1             yes                     26              161.6              123   \n",
       "2              no                      0              243.4              114   \n",
       "\n",
       "   total day charge  ...  total eve calls  total eve charge  \\\n",
       "0             45.07  ...               99             16.78   \n",
       "1             27.47  ...              103             16.62   \n",
       "2             41.38  ...              110             10.30   \n",
       "\n",
       "   total night minutes  total night calls  total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "\n",
       "   total intl minutes  total intl calls  total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "\n",
       "   customer service calls  churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset location\n",
    "file = \"churn_in_telecoms_dataset.csv\"\n",
    "\n",
    "# creating a dataframe\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# shape of the dataset\n",
    "print(df.shape)\n",
    "\n",
    "# snapshot\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d677f",
   "metadata": {},
   "source": [
    "# 0.2 : Feature Engineering and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3dcbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   3333 non-null   object \n",
      " 1   account length          3333 non-null   int64  \n",
      " 2   area code               3333 non-null   int64  \n",
      " 3   phone number            3333 non-null   object \n",
      " 4   international plan      3333 non-null   object \n",
      " 5   voice mail plan         3333 non-null   object \n",
      " 6   number vmail messages   3333 non-null   int64  \n",
      " 7   total day minutes       3333 non-null   float64\n",
      " 8   total day calls         3333 non-null   int64  \n",
      " 9   total day charge        3333 non-null   float64\n",
      " 10  total eve minutes       3333 non-null   float64\n",
      " 11  total eve calls         3333 non-null   int64  \n",
      " 12  total eve charge        3333 non-null   float64\n",
      " 13  total night minutes     3333 non-null   float64\n",
      " 14  total night calls       3333 non-null   int64  \n",
      " 15  total night charge      3333 non-null   float64\n",
      " 16  total intl minutes      3333 non-null   float64\n",
      " 17  total intl calls        3333 non-null   int64  \n",
      " 18  total intl charge       3333 non-null   float64\n",
      " 19  customer service calls  3333 non-null   int64  \n",
      " 20  churn                   3333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 524.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# General information of each column\n",
    "# Including entry types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6c93c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['state', 'account length', 'area code', 'international plan',\n",
      "       'voice mail plan', 'number vmail messages', 'total day minutes',\n",
      "       'total day calls', 'total day charge', 'total eve minutes',\n",
      "       'total eve calls', 'total eve charge', 'total night minutes',\n",
      "       'total night calls', 'total night charge', 'total intl minutes',\n",
      "       'total intl calls', 'total intl charge', 'customer service calls',\n",
      "       'churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# drop the 'phone number' column\n",
    "df = df.drop(columns='phone number')\n",
    "# columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1609368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Unique entries in teh 'churn' column are: [False  True]\n",
      "After conversion, the new converted entries for ease of classfication are: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# finding out entries of the 'churn' column\n",
    "print(f\"The Unique entries in teh 'churn' column are: {df.churn.unique()}\")\n",
    "# >>> array([False,  True])\n",
    "df['churn'] = df['churn'].astype(int)\n",
    "# Convert boolean values in the 'churn' column to integers: False â†’ 0, True â†’ 1\n",
    "print(f\"After conversion, the new converted entries for ease of classfication are: {df.churn.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e926d400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>101.064806</td>\n",
       "      <td>437.182418</td>\n",
       "      <td>8.099010</td>\n",
       "      <td>179.775098</td>\n",
       "      <td>100.435644</td>\n",
       "      <td>30.562307</td>\n",
       "      <td>200.980348</td>\n",
       "      <td>100.114311</td>\n",
       "      <td>17.083540</td>\n",
       "      <td>200.872037</td>\n",
       "      <td>100.107711</td>\n",
       "      <td>9.039325</td>\n",
       "      <td>10.237294</td>\n",
       "      <td>4.479448</td>\n",
       "      <td>2.764581</td>\n",
       "      <td>1.562856</td>\n",
       "      <td>0.144914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.822106</td>\n",
       "      <td>42.371290</td>\n",
       "      <td>13.688365</td>\n",
       "      <td>54.467389</td>\n",
       "      <td>20.069084</td>\n",
       "      <td>9.259435</td>\n",
       "      <td>50.713844</td>\n",
       "      <td>19.922625</td>\n",
       "      <td>4.310668</td>\n",
       "      <td>50.573847</td>\n",
       "      <td>19.568609</td>\n",
       "      <td>2.275873</td>\n",
       "      <td>2.791840</td>\n",
       "      <td>2.461214</td>\n",
       "      <td>0.753773</td>\n",
       "      <td>1.315491</td>\n",
       "      <td>0.352067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.700000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>24.430000</td>\n",
       "      <td>166.600000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>14.160000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.520000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.400000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>201.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.120000</td>\n",
       "      <td>201.200000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>216.400000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>36.790000</td>\n",
       "      <td>235.300000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>235.300000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>10.590000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>350.800000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>59.640000</td>\n",
       "      <td>363.700000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>30.910000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>17.770000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       account length    area code  number vmail messages  total day minutes  \\\n",
       "count     3333.000000  3333.000000            3333.000000        3333.000000   \n",
       "mean       101.064806   437.182418               8.099010         179.775098   \n",
       "std         39.822106    42.371290              13.688365          54.467389   \n",
       "min          1.000000   408.000000               0.000000           0.000000   \n",
       "25%         74.000000   408.000000               0.000000         143.700000   \n",
       "50%        101.000000   415.000000               0.000000         179.400000   \n",
       "75%        127.000000   510.000000              20.000000         216.400000   \n",
       "max        243.000000   510.000000              51.000000         350.800000   \n",
       "\n",
       "       total day calls  total day charge  total eve minutes  total eve calls  \\\n",
       "count      3333.000000       3333.000000        3333.000000      3333.000000   \n",
       "mean        100.435644         30.562307         200.980348       100.114311   \n",
       "std          20.069084          9.259435          50.713844        19.922625   \n",
       "min           0.000000          0.000000           0.000000         0.000000   \n",
       "25%          87.000000         24.430000         166.600000        87.000000   \n",
       "50%         101.000000         30.500000         201.400000       100.000000   \n",
       "75%         114.000000         36.790000         235.300000       114.000000   \n",
       "max         165.000000         59.640000         363.700000       170.000000   \n",
       "\n",
       "       total eve charge  total night minutes  total night calls  \\\n",
       "count       3333.000000          3333.000000        3333.000000   \n",
       "mean          17.083540           200.872037         100.107711   \n",
       "std            4.310668            50.573847          19.568609   \n",
       "min            0.000000            23.200000          33.000000   \n",
       "25%           14.160000           167.000000          87.000000   \n",
       "50%           17.120000           201.200000         100.000000   \n",
       "75%           20.000000           235.300000         113.000000   \n",
       "max           30.910000           395.000000         175.000000   \n",
       "\n",
       "       total night charge  total intl minutes  total intl calls  \\\n",
       "count         3333.000000         3333.000000       3333.000000   \n",
       "mean             9.039325           10.237294          4.479448   \n",
       "std              2.275873            2.791840          2.461214   \n",
       "min              1.040000            0.000000          0.000000   \n",
       "25%              7.520000            8.500000          3.000000   \n",
       "50%              9.050000           10.300000          4.000000   \n",
       "75%             10.590000           12.100000          6.000000   \n",
       "max             17.770000           20.000000         20.000000   \n",
       "\n",
       "       total intl charge  customer service calls        churn  \n",
       "count        3333.000000             3333.000000  3333.000000  \n",
       "mean            2.764581                1.562856     0.144914  \n",
       "std             0.753773                1.315491     0.352067  \n",
       "min             0.000000                0.000000     0.000000  \n",
       "25%             2.300000                1.000000     0.000000  \n",
       "50%             2.780000                1.000000     0.000000  \n",
       "75%             3.270000                2.000000     0.000000  \n",
       "max             5.400000                9.000000     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column Description\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "203ea650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns missing from df.describe(): ['state', 'international plan', 'voice mail plan']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state international plan voice mail plan\n",
       "0    KS                 no             yes\n",
       "1    OH                 no             yes\n",
       "2    NJ                 no              no"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical Columns\n",
    "missing_columns = [col for col in df.columns if col not in df.describe().columns]\n",
    "print(\"Columns missing from df.describe():\", missing_columns)\n",
    "# printing them out\n",
    "df[['state', 'international plan', 'voice mail plan']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c4c6f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of the dataset is: (3333, 20)\n",
      "The 'area code has only 3 entries: [415 408 510]\n"
     ]
    }
   ],
   "source": [
    "# Shape of the datset\n",
    "print(f\"The Shape of the dataset is: {df.shape}\")\n",
    "# 'Area Code' column\n",
    "print(f\"The 'area code has only 3 entries: {df['area code'].unique()}\") # 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b09655",
   "metadata": {},
   "source": [
    "# 1.0 : Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aab2ee",
   "metadata": {},
   "source": [
    "## 1.1: Overview-Introduction: Customer Churn Prediction for SyriaTel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f374e7",
   "metadata": {},
   "source": [
    "This project aims to predict customer churn for `SyriaTel`, a telecommunications company, using a sample of their historical customer data. By building a binary classification model since the customer either churns '1' or does not '0', we shall aim to identify patterns and factors that influence whether a customer will leave the company. The predictive model will assist the company in targeting at-risk customers with `retention strategies`, thereby reducing customer attrition and preserving revenue.\n",
    "\n",
    "The overall project pipeline consists of:\n",
    "\n",
    "1. **Business Understanding**: Understanding churn's impact on SyriaTelâ€™s business.\n",
    "\n",
    "2. **Data Understanding and Preparation**: Exploring the structure and distribution of data. Cleaning, transforming, and encoding the dataset.\n",
    "\n",
    "3. **Exploratory Data Analysis (EDA)**: Finding patterns and feature relationships with churn.\n",
    "\n",
    "4. **Model Building**: Training and tuning classifiers such as Logistic Regression, Decision Trees or Random Forests.\n",
    "\n",
    "5. **Evaluation**: Measuring performance using metrics like accuracy, precision, recall, F1-score, and AUC as well as ROC.\n",
    "\n",
    "6. **Interpretation**: Identifying key drivers of churn.\n",
    "\n",
    "7. **Recommendations and Actionable Insights**: Informing business interventions to reduce churn. Provide recommendations for customer retention based on analytical findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78792fa0",
   "metadata": {},
   "source": [
    "## 1.2: Project-Objectives\n",
    "\n",
    "Here are the key Objectives in this project:-\n",
    "\n",
    "1. **Build a Predictive Model for Churn**  \n",
    "2. **Identify Key Drivers of Churn**  \n",
    "3. **Improve Churn Prediction Accuracy**  \n",
    "4. **Support Retention Strategy Development**  \n",
    "5. **Then Communicate Findings Clearly**: Present model insights and business recommendations in a format accessible to both technical and non-technical stakeholders.\n",
    "\n",
    "However, if time-allows it is also important to explore these other secondary objectives\n",
    "\n",
    "1. **Understand Customer Behavior**  \n",
    "2. **Segment At-Risk Customers**  \n",
    "3. **Evaluate Cost-Benefit Trade-offs**  \n",
    "   Analyze which churn-prone customers are most valuable to retain based on their potential lifetime value.\n",
    "4. **Develop a Repeatable ML Pipeline**  \n",
    "   Build a clean and modular workflow that can be reused with updated customer data in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f67c0",
   "metadata": {},
   "source": [
    "# 2.0 : Business and Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ced04",
   "metadata": {},
   "source": [
    "## 2.1: Business Understanding \n",
    "\n",
    "Customer churn is a critical business challenge for telco compianes such as SyriaTel. In a highly competitive and saturated market, retaining existing customers is often more cost-effective than acquiring new ones. Churn not only impacts immediate revenue but also affects long-term customer lifetime value, brand loyalty, and operational efficiency. Understanding why customers leave â€” and more importantly, identifying who is likely to leave â€” can empower SyriaTel to take timely, targeted actions. These may include `personalized marketing campaigns`, `service improvements`, or `tailored retention offers`. \n",
    "\n",
    "The core business goal of this project is to reduce churn by building a predictive model that accurately flags at-risk customers. This enables SyriaTel to shift from reactive to proactive customer retention, thereby reducing revenue loss and enhancing customer satisfaction.\n",
    "\n",
    "The project aligns with SyriaTel's strategic priorities:\n",
    "\n",
    "1. `Preserving revenue` by minimizing customer loss.\n",
    "\n",
    "2. `Improving customer loyalty` through better engagement.\n",
    "\n",
    "3. `Increasing the return on investment (ROI)` of marketing and support efforts.\n",
    "\n",
    "4. `Leveraging data` to drive smarter, faster business decisions.\n",
    "\n",
    "Ultimately, this project supports SyriaTelâ€™s mission to build lasting customer relationships in a competitive telecom landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db30fb05",
   "metadata": {},
   "source": [
    "## 2.2: Data Understanding\n",
    "\n",
    "The dataset provided by SyriaTel consists of over 3300 customer records and 21 features, each capturing various aspects of a customer's interaction with the company's service. The target variable is `churn`, which indicates whether a customer has discontinued service or not. Understanding the composition and behavior of these column-features is critical in helping us build an effective churn prediction model.\n",
    "\n",
    "1. Several features describe customer demographics and account information, such as `state`, `area code`, and `account length`. While these may not directly cause churn, they can help identify regional trends or the effect of customer tenure on loyalty.\n",
    "\n",
    "2. Other features capture service plans (`international plan`, `voice mail plan`), indicate whether a customer is subscribed to specific services. These features may influence customer satisfaction and costs, potentially affecting their decision to stay or leave.\n",
    "\n",
    "3. A significant portion of the dataset focuses on usage behavior, including `call minutes`, `number of calls`, and `charges` during the day, evening, night, and for international calls. These metrics are split into separate fields for minutes, calls, and charges. This could allow an examinantion of customer engagement and how it relates to churn. However, since charges are typically derived from minutes, some of these columns may be redundant.\n",
    "\n",
    "4. The dataset also includes features such as the number of `customer service calls`, which can be a strong indicator of dissatisfactionâ€”customers who contact support frequently may be more likely to churn.\n",
    "\n",
    "5. Importantly, the dataset is clean, with `no missing values`, and the data types are appropriate for analysisâ€”numerical for continuous variables and object or boolean for categorical ones. However, some preprocessing will be necessary, including encoding categorical variables and dropping non-informative columns like phone number, as done previously, which acts only as an identifier.\n",
    "\n",
    "Through a Thorough EDA, we aim to understand the relationships between these features and the likelihood of churn. Identifying patterns, such as whether certain service plans correlate with higher churn, or whether customers with higher international usage are more likely to leave, will help us build a predictive model and generate actionable business insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3c951",
   "metadata": {},
   "source": [
    "# 3: Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96834fa0",
   "metadata": {},
   "source": [
    "### 3.1 : Handle Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72381781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: It is done!\n"
     ]
    }
   ],
   "source": [
    "# Categories i.e. classify the values in the 'international plan' as either 1 or 0\n",
    "df['international plan'] = df['international plan'].map({'yes': 1, 'no': 0})\n",
    "# Categories i.e. classify the values in the 'voice mail plan' as either 1 or 0\n",
    "df['voice mail plan'] = df['voice mail plan'].map({'yes': 1, 'no': 0})\n",
    "# print feedback that it's done\n",
    "print('Success: It is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b012b059",
   "metadata": {},
   "source": [
    "### 3.2 : Drop Irrelevant or Redundant Columns\n",
    "\n",
    "As mentioned earlier in the overview and business understanding, features like `total day charge` might be redundant if `total day minutes` already provides similar information. You might choose to drop one.\n",
    "\n",
    "- `note:` The feature `phone number` had been dropped already. This is because it only serves as a customer identifier.\n",
    "- `note:` As noted earlier, there are no missing values. See section under `df.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c520c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: It is done!\n"
     ]
    }
   ],
   "source": [
    "# redundant columns\n",
    "redundant_columns = ['total day charge', 'total eve charge', 'total night charge', 'total intl charge']\n",
    "# dropping them\n",
    "df.drop(redundant_columns, axis=1, inplace=True)\n",
    "# print feedback that it's done\n",
    "print('Success: It is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c426f77",
   "metadata": {},
   "source": [
    "### 3.3 : Standardization \n",
    "\n",
    "Now, we transform features in the datasset i.e. `total day minutes`, `number vmail messages`, `total eve minutes` so that they have a common scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ff3bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: It is done!\n"
     ]
    }
   ],
   "source": [
    "# Create a scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Choice of columns to standadise\n",
    "cols_to_standardize = ['total day minutes', 'number vmail messages', 'total eve minutes']\n",
    "\n",
    "# Apply standardization to relevant columns\n",
    "df[cols_to_standardize] = scaler.fit_transform(df[cols_to_standardize])\n",
    "\n",
    "# print feedback that it's done\n",
    "print('Success: It is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54752742",
   "metadata": {},
   "source": [
    "### 3.4 : Feature Engineering\n",
    "\n",
    "- Since the dataset is riddled with `minutes`, suppose we have `Total Call Usage` i.e the sum of `total day minutes`, `total eve minutes`, `total night minutes`, and `total intl minutes`. \n",
    "\n",
    "- Also, we can have `Average Call Duration` i.e. for Average of `day`, `evening`, `night`, and `international minutes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7212fbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: It is done!\n"
     ]
    }
   ],
   "source": [
    "# TOTAL CALL USAGE:\n",
    "df['total minutes'] = df['total day minutes'] + df['total eve minutes'] + df['total night minutes'] + df['total intl minutes']\n",
    "# AVERAGE CALL DURATION:\n",
    "df['average call duration'] = df[['total day minutes', 'total eve minutes', 'total night minutes', 'total intl minutes']].mean(axis=1)\n",
    "# print feedback that it's done\n",
    "print('Success: It is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89198a09",
   "metadata": {},
   "source": [
    "### 3.5 : Choosing `Target` and `Feature` column(s)\n",
    "\n",
    "It is obvious that the choice of our Target column is `churn` while the rest are automatically the `Features`.\n",
    "\n",
    "Now, Splitting the Data into `Training` and `Test` dataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a08083dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: It is done!\n"
     ]
    }
   ],
   "source": [
    "# Target Feature ## Dependent Feature\n",
    "y = df.churn\n",
    "# Other Features ## independent Features\n",
    "X = df.drop('churn', axis=1)\n",
    "# split-test-code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "# print feedback that it's done\n",
    "print('Success: It is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d64ea",
   "metadata": {},
   "source": [
    "### 3.6 : Check for Class Imbalance\n",
    "\n",
    "Let's ensure that the model doesnâ€™t learn misleading patterns â€” especially because we have binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "214f555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Value counts are: \n",
      "0    2850\n",
      "1     483\n",
      "Name: churn, dtype: int64\n",
      "\n",
      "Essentially, that is:-\n",
      "0    0.855086\n",
      "1    0.144914\n",
      "Name: churn, dtype: float64\n",
      " \n",
      "INFERENCE: So, only 14.49% of the customers churn â€” this shows class imbalance.\n"
     ]
    }
   ],
   "source": [
    "# first, let's check class distribution\n",
    "print(f\"The Value counts are: \\n{df.churn.value_counts()}\", end = '\\n\\n')\n",
    "# The proportions are:\n",
    "print('Essentially, that is:-', end = '\\n')\n",
    "print(f\"{df['churn'].value_counts(normalize=True)}\", end = '\\n')\n",
    "# Inference and Conclusion \n",
    "churn_perc = round(df['churn'].value_counts(normalize=True)[1] * 100, 2)\n",
    "# print the result\n",
    "print(' ')\n",
    "print(f\"INFERENCE: So, only {churn_perc}% of the customers churn â€” this shows class imbalance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe23246",
   "metadata": {},
   "source": [
    "#### `Inference`: \n",
    "\n",
    "This class imbalance refers to the fact that one class (non-churn) significantly outweighs the other `churning` group. This imbalance can affect the performance of machine learning model. They may become biased toward predicting the majority class, the `non-churning`, which could result in misleading accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac105a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RE_DONE\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)  # drop_first avoids dummy trap\n",
    "\n",
    "# \n",
    "le = LabelEncoder()\n",
    "X['state'] = le.fit_transform(X['state'])\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "237559c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       570\n",
      "           1       0.57      0.59      0.58        97\n",
      "\n",
      "    accuracy                           0.88       667\n",
      "   macro avg       0.75      0.76      0.75       667\n",
      "weighted avg       0.88      0.88      0.88       667\n",
      "\n",
      "ROC-AUC Score: 0.8444112859468258\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Encode categorical variables (e.g., 'State', 'Gender', etc.)\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)  # One-Hot Encoding\n",
    "\n",
    "# Step 2: Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Apply SMOTE to oversample the minority class in the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 4: Train a Random Forest Classifier with class weights to handle class imbalance\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 6: Evaluate the model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705db17",
   "metadata": {},
   "source": [
    "# 4: Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba75258",
   "metadata": {},
   "source": [
    "#### 4.1 : Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68acbc",
   "metadata": {},
   "source": [
    "Let us start with a `simple Logistic Regression` model, before we try others like Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac4b365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rurig\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')  # Use class_weight if you didn't use SMOTE\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b235c1",
   "metadata": {},
   "source": [
    "#### 4.2 : Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48ad86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Feature Scaling (optional, but needed for SVM, KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791713d",
   "metadata": {},
   "source": [
    "#### 4.3 : Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fae365a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Logistic Regression -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.85       570\n",
      "           1       0.35      0.74      0.48        97\n",
      "\n",
      "    accuracy                           0.76       667\n",
      "   macro avg       0.65      0.75      0.66       667\n",
      "weighted avg       0.86      0.76      0.79       667\n",
      "\n",
      "ROC AUC: 0.8154277446192801\n",
      "\n",
      "----- Random Forest -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       570\n",
      "           1       0.89      0.56      0.68        97\n",
      "\n",
      "    accuracy                           0.93       667\n",
      "   macro avg       0.91      0.77      0.82       667\n",
      "weighted avg       0.92      0.93      0.92       667\n",
      "\n",
      "ROC AUC: 0.9024507144149033\n",
      "\n",
      "----- KNN -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93       570\n",
      "           1       0.70      0.31      0.43        97\n",
      "\n",
      "    accuracy                           0.88       667\n",
      "   macro avg       0.80      0.64      0.68       667\n",
      "weighted avg       0.86      0.88      0.86       667\n",
      "\n",
      "ROC AUC: 0.7735756918068367\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=10000),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    # \"XGBoost\": XGBClassifier(scale_pos_weight=6, use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    # \"SVM\": SVC(class_weight='balanced', probability=True, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    if name in [\"SVM\", \"KNN\"]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b293c058",
   "metadata": {},
   "source": [
    "# 5: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d12aa",
   "metadata": {},
   "source": [
    "After training the model, it's important to evaluate its performance using:\n",
    "\n",
    "1. `Accuracy`: The percentage of correct predictions.\n",
    "\n",
    "2. `Confusion Matrix`: \n",
    "\n",
    "    - Helps you understand the modelâ€™s performance with respect to false positives, false negatives, true positives, and true negatives.\n",
    "\n",
    "3. `Precision, Recall, F1-Score`: \n",
    "    - Especially important for imbalanced datasets or when the costs of false positives/negatives differ.\n",
    "\n",
    "4. `ROC-AUC Curve`: Evaluate the classifierâ€™s ability to distinguish between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# Random Forest\n",
    "\n",
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f4eeb",
   "metadata": {},
   "source": [
    "# 6: Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a22ab4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
